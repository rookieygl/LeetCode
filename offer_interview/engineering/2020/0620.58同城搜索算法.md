算法、模型训练方向。

# 建模算法

逻辑回归（lr）

# 分词算法

中文分词有三类：基于字符串匹配的分词方法、基于理解的分词方法和基于统计的分词方法。

## 基于最大匹配算法

基于词典,有正向匹配、后向匹配、双向匹配。

最大匹配方法分词的效果取决于分词词典的大小与质量，分词的原则是尽量避免单个字的出现和尽可能少的分词数量

### 最大正向匹配

- 从左到右取待切分汉语句的m个字符作为匹配字段，m为词典中最长词条个数。
- 查找词典并进行匹配，若匹配成功，则将这个匹配字段作为一个词切分出来。

### 最大后向匹配

- 从右到左切分汉语句的m个字符作为匹配字段，m为词典中最长词条个数。
- 查找词典并进行匹配。若匹配成功，则将这个匹配字段作为一个词切分出来。

### 双向最大向前匹配

- 将正向最大匹配法得到的分词结果和逆向最大匹配法得到的结果进行比较，从而决定正确的分词方法。
- 启发式规则：1.如果正反向分词结果词数不同，则取分词数量较少的那个。2.如果分词结果词数相同。a.分词结果相同，就说明没有歧义，可返回任意一个。 b.分词结果不同，返回其中单字较少的那个。



## n-gram

基于这样一种假设，第n个词的出现只与前面N-1个词相关，而与其它任何词都不相关。是语言判别模型，需要大量数据训练。

比如：输入了一个滴滴，联想到打车。

实现可以通过马尔科夫假设，需要注意语言模型直接对句子的概率建模，是一个判别模型。

- 根据语料获取每个词出现频次与每个词后接词语出现频次
- 寻找当前字的最佳前驱节点，并记录累计概率。



## HMM（隐马尔可夫模型）

可用于序列标注问题的统计学模型。

隐马尔可夫模型的3个关键矩阵：初始概率矩阵、状态转移概率矩阵、发射概率矩阵。

- 根据训练样本获取每个词的状态（S：单字词， B：词的开头，M：词的中间，E：词的末尾）
- 如果是单字词，则记录第一个字的状态，用于计算初始状态概率。如果不是单字词，则统计状态转移次数，并计算对应的概率。
- 通过上面步骤得到3个概率矩阵，并且由训练样本可得可观测序列，通过维特比算法（Viterbi）来求得在马尔可夫模型中最优的隐含状态。维特比算法其实就是一个求最短路径的动态规划问题。





# 算法题

**一个无序整数数组，将其分成两个总和尽量相等的数组**

