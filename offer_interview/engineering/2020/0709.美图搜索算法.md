# 一面

## 1.自我介绍

## 2.ES集群介绍

### 集群数据量

200t数据：1t数据对应1g内存，存7天，对应200g倒排索引内存。

20台机器：每台机器30g内存。只给10g内存为倒排内存。

### 集群多少个索引，分片

31个索引，分片数据量最大50g，只要一份副本。

如果需要修改分片数牵涉索引重建。

索引重建方法：

```java
POST _reindex
{
  "source": {
    "index": "old_index"
  },
  "dest": {
    "index": "new_index"
  }
}
```



### 集群document数量

1t一亿数据，200亿数据。




## 3.es核心原理

### 什么是索引

索引就是搜索的入口。索引是由一定的数据结构实现的，如hash，二叉树。

在关系数据库中，索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构。

**索引的作用**

- 保证数据的准确性

　　唯一的索引值对应着唯一的数据。

- 加快检索速度

　　索引可以极大加快检索速度。



#### 索引的数据结构

​	es是hash索引，数据库是b+树。

​	有必要学习数据库索引。



#### shard，segment和索引的关系

​	一个索引分成1至多个shard（主分片，分片副本默认为1）。

​	elasticsearch中的 一个shard就是一个Lucene实例，是一个完整的搜索引擎。

​	每个分片关联多个segment，每一个segment都是一个倒排索引，辅助索引引擎进行文档相关度评分和文旦检索。



#### 索引磁盘文件拓展名已经对应的作用

| 文件后缀   | 说明                                                         |
| ---------- | ------------------------------------------------------------ |
| .si        | segment元信息文件，记录了segment的文档数量和对应的文档列表等信息。 |
| .fnm       | fields基本信息，包括field的数量，field的类型，以及IndexOpetions，包括是否存储、是否索引，是否分词，是否需要列存等等。 |
| .fdx, .fdt | 正排索引数据存储文件 .fdx为索引文件 .fdt为数据文件。         |
| .tip, .tim | 倒排索引数据存储文件 .tip为索引文件 .tim为数据文件。         |
| .doc, .pos | .doc保存了每个term的doc id列表和term在doc中的词频 ； .pos文件，保存了term在doc中的位置。 |
| .dvm, .dvd | docvalues文件 .dvm为索引文件 .dvd 为数据文件。               |
| .cfe .cfs  | 联合文件 .cfe为索引文件 .cfs 为数据文件 ,.cfe文件保存Lucene各文件在.cfs文件的位置信息。 |
| .del       | 被删除文档的id集合文件，被删除和更新的文档依旧可以被搜索到，只是会在返回结果中别过滤。 |



### 倒排索引

了解倒排索引，先了解一些索引的基本元素。

- 文件和文档编号(Document ID)

  一个文档对应一个唯一文档编号，es默认是字符串，可以指定为数值，逻辑自增长。相同id的文档会被覆盖

  

- 词元和词元序号(Word ID)

  每个独立词元，必然对应一个唯一词元序号，用于判断词典是否存在。

  读写分词默认standard分词器（es默认为luncence的token analyzer）。**建议词元的写是分词和读时分词保持一致。这样才能保证词元的最大匹配。**

  

  词元是按字符顺序排列的（lucene没有使用B树结构），因此lucene可以用二分搜索算法快速定位词元。

  

- 词元频率

  单词在文档中出现的次数。这是相关度的最基本条件，根据词元在不同文档的词频结合相关度算法得出相关度得分。

  

- POS 词元位置

  词元在文档中出现的位置，用于词元词组查询，紧密度计算。

  

​	实现时Lucene将上面信息分成三列分别作为词典文件（Term Dictionary）、频率文件（Frequencies Dictionary）、位置文件（Positions Dictionary）保存。



​	**倒排索引**是实现“单词-文档矩阵”的一种具体存储形式，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：“单词词典”和“倒排文件”。



单词词典是在内存中的，倒排文件(Inverted File)自然是能被词典关联的磁盘文件，通常是二进制文件。



#### 单词词典

单词词典由词元和词元序号组成，单词词典记录已经存在的词元，并且记录频率文件和位置文件的指针。

在新增数据时，根据词元是否存在，判断倒排索引需要新增词元。





#### 倒排文件(Inverted File)

**倒排列表(PostingList)：**倒排列表记载了出现过某个单词的所有文档列表及单词在该文档中出现的位置信息(POS)，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。

所有单词的**倒排列表**往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。

倒排文件的类型参考索磁盘文件扩展名。





#### 倒排索引压缩算法

为了减小索引文件的大小，Lucene对索引还使用了压缩技术。

首先，对词典文件中的关键词进行了压缩，关键词压缩为<前缀长度，后缀>，例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为<3，语>。

其次大量用到的是对数字的压缩，数字只保存与上一个值的差值（这样可以减小数字的长度，进而减少保存该数字需要的字节数）。例如当前文章号是16389（不压缩要用3个字节保存），上一文章号是16382，压缩后保存7（只用一个字节）。



#### 倒排索引建立的过程

词元提取，简历词元和文档的关联，重复词元，文档关联到已经存在的相同词元，构建倒排列表即可。



#### 推荐词实现，联想词





### es的四种搜索方式

不是难点，体现在对es的理解

Query And Fetch

Query Then Fetch



### 分片搜索方式

- randomizeacross shards
   随机选择分片查询数据，es的默认方式，有可能数据失真，不完整。

- _local
   优先在本地节点上的分片查询数据然后再去其他节点上的分片查询，本地节点没有IO问题，可能造成负载不均问题。数据量是完整的。

- _primary
   只在主分片中查询不去副本查，一般数据完整。

- _primary_first
   优先在主分片中查，如果主分片挂了则去副本查，一般数据完整。

- _only_node
   只在指定id的节点中的分片中查询，数据可能不完整。

- _prefer_node
   优先在指定你给节点中查询，一般数据完整。

- _shards
   在指定分片中查询，数据可能不完整。

- _only_nodes
   可以自定义去指定的多个节点查询，es不提供此方式需要改源码。

## 4.JAVA

#### 技术栈，核心技能

介绍自己熟悉的技术。

#### 栈溢出StackOverflowError

栈的个数和栈帧的深度

栈就是线程栈，栈的个数上限受jvm内存和栈大小两个参数控制

正则，超大字符串解析，会让栈溢出

#### jvm分区



## 5.算法

#### 加权算法

​	bm25，tf-idf，norms（字段归一值）

#### 意图识别



#### 分词算法



#### cv算法

#### NLP算法和应用


## 6.职业规划

面试官介绍公司业务，问你发展方向

业务方向，算法方向



合适的回答是专注业务实现，然后不断挑战算法的高度。



# 二面

## 1.搜索算法

#### DF/TDF

​	TDF公式：

#### 泛滥词，罕见词权重问题



s

## 2.es搜索引擎

#### 数据库双写

mysql-->cat-->logstash-->es

logstash：有输入，有输出。



#### 分片设计





## 3.JAVA

#### 主要开发语言

要弄清楚对方公司用的什么语言，再接着聊

#### final关键字

#### 设计模式

**单例设计模式**

手写，建议写静态内部类单例。

**装饰者模式**

**工厂模式**

#### TCP/IP

三次握手/四次断开，wait_time和close_time

## 4.搜索系统

#### 搜索指标优化

#### 搜索效果提升

## 5.算法

#### 二叉树的遍历

- 广度遍历（层次遍历）

  

- 深度遍历（一般是中序）

  递归代码比较简单

#### 大数据对比

从大数据中如何快速判断数据是否存在

- hash搜索和布隆过滤器

  布隆过滤器是`由一个很长的bit数组和一系列哈希函数组成的`，数组的每个元素都只占1bit空间，并且每个元素只能为0或1。这种比较巧妙的概率型数据结构，特点是高效地插入和查询，可以用来告诉你**某样东西一定不存在或者可能存在**。

  哈希函数有两个要求：

  1. hash结果尽可能的分散
  2. 结果不能超过数组边界

  

  **布隆的运算过程**：新的数据进来，通过不同的hash函数计算，然后写进数组，写入成功的元素改为1。过滤时，根据过滤值和相同函数计算出数组位置，只要有一个元素为0,那么该元素一定不存在。再大数据量场景下，hash冲突产生可能存在的情况。

  

  对于布隆过滤器的判断结果，不存在的结果是精确的，可能存在有一定误差，误差来自hash冲突，hash冲突的原因有：

  1. 数组的长度

     数组越长，数据越分散。

  2. hash函数的个数和结果散列情况

     如果有三个函数，就会存三个位置，这样的好处是消除一个hash函数带来的误差。当然hash函数也不是越多越好。



- 二叉树

  二叉树（构建成本较高:维护平衡，存储空间）

  

# 6.网络

## TCP/IP

## 三次握手/四次断开

## Close_Time和Wait_Time

